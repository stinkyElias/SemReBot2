{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HF_HOME'] = '/home/stinky/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'output'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "tiny_dataset = load_dataset('json', data_files='single_output_10_samples.jsonl')\n",
    "tiny_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'output'],\n",
       "        num_rows: 8\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input', 'output'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split tiny_dataset into train and eval 80/20\n",
    "tiny_dataset = tiny_dataset['train'].train_test_split(test_size=0.2, seed=42)\n",
    "tiny_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ed9a42a5ea454dbd265740405e61b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "device = 'cuda:0'\n",
    "base_model_id = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=nf4_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompt(example):\n",
    "    text = f\"### Question: {example['input']}\\n ### Answer: {example['output']}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_and_tokenize_prompt(prompt):\n",
    "    return tokenizer(formatting_prompt(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d336c5c79c489281fade6aa4c6a5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df7921d8e44441687a688b2f0b988cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = tiny_dataset['train'].map(generate_and_tokenize_prompt)\n",
    "tokenized_val_dataset = tiny_dataset['test'].map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 85041152 || all params: 3837112320 || trainable%: 2.2162799758751914\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MistralForCausalLM(\n",
       "      (model): MistralModel(\n",
       "        (embed_tokens): Embedding(32000, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x MistralDecoderLayer(\n",
       "            (self_attn): MistralSdpaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (rotary_emb): MistralRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): MistralMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=14336, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): MistralRMSNorm()\n",
       "            (post_attention_layernorm): MistralRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): MistralRMSNorm()\n",
       "      )\n",
       "      (lm_head): lora.Linear(\n",
       "        (base_layer): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (default): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (default): Linear(in_features=32, out_features=32000, bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)\n",
    "\n",
    "model = accelerator.prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You cannot perform fine-tuning on purely quantized models. Please attach trainable adapters on top of the quantized model to correctly perform fine-tuning. Please see: https://huggingface.co/docs/transformers/peft for more details",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m run_name \u001b[38;5;241m=\u001b[39m base_model_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m project\n\u001b[1;32m      7\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/stinky/models/hub/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m run_name\n\u001b[0;32m----> 9\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtransformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenized_train_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenized_val_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_checkpointing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2.5e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Want a small lr for finetuning\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbf16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpaged_adamw_8bit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# When to start reporting loss\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogging_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./logs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Directory for storing logs\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# Save the model checkpoint every logging step\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# Save checkpoints every 50 steps\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Evaluate the model every logging step\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m# Evaluate and save checkpoints every 50 steps\u001b[39;49;00m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# Perform evaluation at the end of training\u001b[39;49;00m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreport_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwandb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# Comment this out if you don't want to use weights & baises\u001b[39;49;00m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrun_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrftime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mH-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# Name of the W&B run (optional)\u001b[39;49;00m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataCollatorForLanguageModeling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# silence the warnings. Please re-enable for inference!\u001b[39;00m\n\u001b[1;32m     37\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/miniconda3/envs/falcon/lib/python3.11/site-packages/transformers/trainer.py:440\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;66;03m# At this stage the model is already loaded\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_quantized_and_base_model \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_peft_model(model):\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot perform fine-tuning on purely quantized models. Please attach trainable adapters on top of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m the quantized model to correctly perform fine-tuning. Please see: https://huggingface.co/docs/transformers/peft\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for more details\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    444\u001b[0m     )\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_quantized_and_base_model \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _quantization_method_supports_training:\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model you are trying to fine-tune is quantized with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mhf_quantizer\u001b[38;5;241m.\u001b[39mquantization_config\u001b[38;5;241m.\u001b[39mquant_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but that quantization method do not support training. Please open an issue on GitHub: https://github.com/huggingface/transformers\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to request the support for training support for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mhf_quantizer\u001b[38;5;241m.\u001b[39mquantization_config\u001b[38;5;241m.\u001b[39mquant_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: You cannot perform fine-tuning on purely quantized models. Please attach trainable adapters on top of the quantized model to correctly perform fine-tuning. Please see: https://huggingface.co/docs/transformers/peft for more details"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "project = \"pddl_tiny_dataset\"\n",
    "base_model_name = \"mistral\"\n",
    "run_name = base_model_name + \"_\" + project\n",
    "output_dir = '/home/stinky/models/hub/' + run_name\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=1,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        max_steps=500,\n",
    "        learning_rate=2.5e-5, # Want a small lr for finetuning\n",
    "        bf16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=25,              # When to start reporting loss\n",
    "        logging_dir=\"./logs\",        # Directory for storing logs\n",
    "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "        save_steps=25,                # Save checkpoints every 50 steps\n",
    "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
    "        eval_steps=25,               # Evaluate and save checkpoints every 50 steps\n",
    "        do_eval=True,                # Perform evaluation at the end of training\n",
    "        report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = True  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "falcon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
