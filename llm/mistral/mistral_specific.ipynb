{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "import gc\n",
    "import sys\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "device = 'cuda'\n",
    "model_id = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "904dcf2fc4bb48ff995e998ed2d574aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=nf4_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('shots.jsonl', 'r') as infile:\n",
    "    data = json.load(infile)\n",
    "\n",
    "domains, commands, solutions = [], [], []\n",
    "\n",
    "for i in range(len(data['shots'])):\n",
    "    domains.append(data['shots'][i]['domain'])\n",
    "    commands.append(data['shots'][i]['command'])\n",
    "    solutions.append(data['shots'][i]['solution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_knowledge = 'instance tars robot|instance charging_station zone|instance unload_zone zone|instance shelf_1 zone|instance shelf_2 zone|instance shelf_3 zone|instance shelf_4 zone|predicate robot_availabletars|predicate is_recharge_zone charging_station|predicate is_unload_zone unload_zone|predicate is_shelf_zone shelf_1|predicate is_shelf_zone shelf_2|predicate is_shelf_zone shelf_3|predicate is_shelf_zone shelf_4|'\n",
    "system_prompt = f'You are the robot tars, an automatic forklift that will move pallets around a warehouse. Your task is to outline the available instances, predicates, and goals based on the provided domain and command. Answer in the format shown after ### Output ###. This is the domain: {domains[0]}.'\n",
    "\n",
    "messages = [{'role': 'user', 'content': system_prompt + f'At all times, these instances and predicates are true: {generated_knowledge}. You do not have to repeat them in your output.' + f' Here is a command {commands[0]}. ### Output ### {solutions[0]}.'},\n",
    "            {'role': 'assistant', 'content': 'Understood. Awaiting new domain and command.'},\n",
    "]\n",
    "\n",
    "for i in range(1, len(data['shots'])):\n",
    "    messages.append({'role': 'user', 'content': f'Command: {commands[i]}'})\n",
    "    messages.append({'role': 'assistant', 'content': f'### Output ### {solutions[i]}'})\n",
    "\n",
    "command = 'Move the three new pallets from the unload zone to shelf 4.'\n",
    "messages.append({'role': 'user', 'content': f'Command: {command}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodeds = tokenizer.apply_chat_template(messages, return_tensors='pt')\n",
    "inputs = encodeds.to(device)\n",
    "generated_ids = model.generate(inputs, pad_token_id=tokenizer.eos_token_id, max_new_tokens=1000, do_sample=True)\n",
    "decoded = tokenizer.batch_decode(generated_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = '[/INST]'\n",
    "start_tag_index = decoded[0].rfind(start_token)\n",
    "decoded[0] = decoded[0][start_tag_index+len(start_token):]\n",
    "\n",
    "end_token = '</s>'\n",
    "end_tag_index = decoded[0].rfind(end_token)\n",
    "decoded[0] = decoded[0][:end_tag_index]\n",
    "\n",
    "delimiter = '|'\n",
    "last_delimiter_index = decoded[0].rfind(delimiter)\n",
    "decoded[0] = decoded[0][:last_delimiter_index+len(delimiter)]\n",
    "\n",
    "output_token = '### Output ###'\n",
    "output_tag_index = decoded[0].find(output_token)\n",
    "decoded[0] = decoded[0][output_tag_index+len(output_token)+1:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "falcon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
