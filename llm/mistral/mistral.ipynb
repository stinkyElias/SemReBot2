{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/cluster/work/eliashk/models/mistral/full_precision/'\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('mistralai/Mistral-7B-Instruct-v0.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98aba84c9a3e44549192a6c94cd024a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('mistralai/Mistral-7B-Instruct-v0.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = [\n",
    "    \"Drive forward 1 meter\",\n",
    "    \"Drive backward 4 meters\",\n",
    "    \"Turn 45 degrees to the left\",\n",
    "    \"Turn 13 degrees to the right\",\n",
    "    \"Drive backward 7 meters\",\n",
    "    \"Drive forward 2 meters\",\n",
    "    \"I like to eat ice cream\",\n",
    "    \"Now I think it's time for you to drive forward 5 meters\",\n",
    "    \"After much thought, I have decided that you should turn 87 degrees to the left\",\n",
    "    \"The pyramids in Egypt were built a long time ago\",\n",
    "    \"Eight pots of gold are enough to buy a new car\",\n",
    "    \"Yep, I agree that you should drive backward 3 meters\",\n",
    "    \"Ugh, now I've had enough of driving forward 1 meter. Drive backward 2 meters\",\n",
    "    \"No, don't drive backward. Turn 30 degrees to the right first\",\n",
    "    \"Okay, now it's time for you to drive forward 4 meters\",\n",
    "    \"Just turn 56 degrees to the right\",\n",
    "    \"If you can jump on a pogo stick, you can jump on a pogo stick. Turn 4 degrees to the left\",\n",
    "    \"Drive backward 8 meters. Whistle a tune while you do it\",\n",
    "    \"Back to the start. Drive forward 1 meter\",\n",
    "    \"Turn to the right\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward|1|m\n",
      "backward|4|m\n",
      "left|45|d\n",
      "right|13|d\n",
      "backward|7|m\n",
      "forward|2|m\n",
      "error\n",
      "forward|5|m\n",
      "left|87|d\n",
      "error\n",
      "error\n",
      "\n",
      "(This robot is designed to follow driving instructions and cannot process or understand information about buying a car or pots of gold.)\n",
      "error (I cannot check or agree to anything, I can only respond based on instructions given to me.)\n",
      "\n",
      "forward|3|m (based on the instruction given in the first line of this conversation)\n",
      "backward|2|m\n",
      "right|30|d\n",
      "\n",
      "Then: forward|magnitude|m (depending on the distance you want to cover after the turn)\n",
      "forward|4|m\n",
      "right|56|d\n",
      "error (I am a differential drive robot and I cannot jump on a pogo stick, nor can I turn directly, I can only drive forward, backward, rotate left or right.)\n",
      "error (I cannot whistle a tune as I am a text-based robot.)\n",
      "\n",
      "forward|8|m (But I can drive backward if instructed.)\n",
      "forward|1|m\n",
      "right|error|u (Unit not specified)\n",
      "\n",
      "Note: In my previous answer, I assumed that you want to give me a driving instruction. Since your new question is about checking the bank account balance, which is not related to my driving instructions, I returned an error message instead.\n",
      "30040678400\n"
     ]
    }
   ],
   "source": [
    "for command in commands:\n",
    "    messages = [\n",
    "        {'role': 'user', 'content': 'You are a differential drive robot called Turtle. You can drive forward, backward, rotate left and rotate right. You receive instructions where you will drive. You can only answer in the following format: \\\"verb|magnitude|unit\\\". You task: process instructions, output correct verb, magnitude and unit in correct format. If you cannot find a response, answer \\\"error\\\" and never ever anything else. To rotate, left/right to correct angle. To drive, forward/backward for x meters.'},\n",
    "        {'role': 'assistant', 'content': 'My name is Turtle and I am a differential drive robot.'},\n",
    "        {'role': 'user', 'content': 'Drive forward for 14 meters.'},\n",
    "        {'role': 'assistant', 'content': 'forward|14|m'},\n",
    "        {'role': 'user', 'content': 'Rotate left for 90 degrees.'},\n",
    "        {'role': 'assistant', 'content': 'left|90|d'},\n",
    "        {'role': 'user', 'content': 'I want to buy a new car. Check how much money I have in my bank account.'},\n",
    "        {'role': 'assistant', 'content': 'error'},\n",
    "        {'role': 'user', 'content': command}\n",
    "    ]\n",
    "\n",
    "    encodeds = tokenizer.apply_chat_template(messages, return_tensors='pt')\n",
    "\n",
    "    model_inputs = encodeds.to(device)\n",
    "    model.to(device)\n",
    "\n",
    "    generated_ids = model.generate(model_inputs, pad_token_id=tokenizer.eos_token_id, max_new_tokens=100, do_sample=True)\n",
    "    decoded = tokenizer.batch_decode(generated_ids)\n",
    "\n",
    "    # Remove the pre-prompts and end-of-sentence token\n",
    "    output_tokens = decoded[0]\n",
    "    end_token = \"[/INST]\"\n",
    "\n",
    "    # Find last occurence of end_tag in output\n",
    "    end_tag_index = output_tokens.rfind(end_token)\n",
    "    end_of_sentence = -4\n",
    "    sliced_output = output_tokens[end_tag_index + len(end_token):end_of_sentence]\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(sliced_output)\n",
    "    \n",
    "print(model.get_memory_footprint())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
