{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/home/stinky/Documents/semantic-robot/ros2_ws/src/mistral_interface/model'\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "device = 'cuda'\n",
    "model_id = 'mistralai/Mistral-7B-v0.1'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('mistralai/Mistral-7B-v0.1', device_map='auto', load_in_4bit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf4_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nf4 = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=nf4_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = [\n",
    "    \"Drive forward 1 meter\",\n",
    "    \"Drive backward 4 meters\",\n",
    "    \"Turn 45 degrees to the left\",\n",
    "    \"Turn 13 degrees to the right\",\n",
    "    \"Drive backward 7 meters\",\n",
    "    \"Drive forward 2 meters\",\n",
    "    \"I like to eat ice cream\",\n",
    "    \"Now I think it's time for you to drive forward 5 meters\",\n",
    "    \"After much thought, I have decided that you should turn 87 degrees to the left\",\n",
    "    \"The pyramids in Egypt were built a long time ago\",\n",
    "    \"Eight pots of gold are enough to buy a new car\",\n",
    "    \"Yep, I agree that you should drive backward 3 meters\",\n",
    "    \"Ugh, now I've had enough of driving forward 1 meter. Drive backward 2 meters\",\n",
    "    \"No, don't drive backward. Turn 30 degrees to the right first\",\n",
    "    \"Okay, now it's time for you to drive forward 4 meters\",\n",
    "    \"Just turn 56 degrees to the right\",\n",
    "    \"If you can jump on a pogo stick, you can jump on a pogo stick. Turn 4 degrees to the left\",\n",
    "    \"Drive backward 8 meters. Whistle a tune while you do it\",\n",
    "    \"Back to the start. Drive forward 1 meter\",\n",
    "    \"Turn to the right\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for command in commands:\n",
    "    messages = [\n",
    "        {'role': 'user', 'content': 'You are a differential drive robot called Turtle. You can drive forward, backward, rotate left and rotate right. You receive instructions where you will drive. You can only answer in the following format: \\\"verb|magnitude|unit\\\". You task: process instructions, output correct verb, magnitude and unit in correct format. If you cannot find a response, answer \\\"error\\\" and never ever anything else. To rotate, left/right to correct angle. To drive, forward/backward for x meters.'},\n",
    "        {'role': 'assistant', 'content': 'My name is Turtle and I am a differential drive robot.'},\n",
    "        {'role': 'user', 'content': 'Drive forward for 14 meters.'},\n",
    "        {'role': 'assistant', 'content': 'forward|14|m'},\n",
    "        {'role': 'user', 'content': 'Rotate left for 90 degrees.'},\n",
    "        {'role': 'assistant', 'content': 'left|90|d'},\n",
    "        {'role': 'user', 'content': 'I want to buy a new car. Check how much money I have in my bank account.'},\n",
    "        {'role': 'assistant', 'content': 'error'},\n",
    "        {'role': 'user', 'content': command}\n",
    "    ]\n",
    "\n",
    "    encodeds = tokenizer.apply_chat_template(messages, return_tensors='pt')\n",
    "\n",
    "    model_inputs = encodeds.to(device)\n",
    "    # model.to(device)\n",
    "\n",
    "    generated_ids = model.generate(model_inputs, pad_token_id=tokenizer.eos_token_id, max_new_tokens=100, do_sample=True)\n",
    "    decoded = tokenizer.batch_decode(generated_ids)\n",
    "\n",
    "    # Remove the pre-prompts and end-of-sentence token\n",
    "    output_tokens = decoded[0]\n",
    "    end_token = \"[/INST]\"\n",
    "\n",
    "    # Find last occurence of end_tag in output\n",
    "    end_tag_index = output_tokens.rfind(end_token)\n",
    "    end_of_sentence = -4\n",
    "    sliced_output = output_tokens[end_tag_index + len(end_token):end_of_sentence]\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(sliced_output)\n",
    "    \n",
    "print(model.get_memory_footprint())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
